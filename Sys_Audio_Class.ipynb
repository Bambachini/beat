{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on9fgTUcr-7r"
      },
      "source": [
        "# System Neuroscience - Sound localization\n",
        "\n",
        "This is a Jupyter Notebook. The code you see is written in [Python 3](https://www.python.org/).\n",
        "\n",
        "Audio samples in this Notebook are to be played via headphones or earphones to enable perception of __binaural sound localization cues__.\n",
        "\n",
        "<div style=\"border: 5px solid red; color: black; padding: 0.5em; margin: 1em;\"><strong>WARNING:</strong><br>The Audio-Elements in Jupyter Notebooks may play very loud sounds.<br>You should <strong>turn down the volume</strong> in your operating system (Windows/macOS) or the media volume when using a phone.<br>Increase volume stepwise, starting with a low level until you can hear the audio samples just fine.<br><strong>Be careful to avoid noise damage or discomfort!</strong></div>\n",
        "\n",
        "## Just view it and play Audio samples:\n",
        "\n",
        "When you open the Notebook in a suitable environment that renders it correctly, the output `<Audio>` elements should be shown in your browser right away as they are saved together with the Notebook.\n",
        "\n",
        "If you have no Python/Jupyter installed on your computer, just visit:\n",
        "\n",
        "https://colab.research.google.com/github/penalab/systems-sound-localization/blob/master/Sys_Audio_Class.ipynb\n",
        "\n",
        "A \"static\" export of this notebook is also available (but may be removed without further notice in the future):\n",
        "\n",
        "https://elpy.de/class/Sys_Audio_Class.html\n",
        "\n",
        "## Play with parameters:\n",
        "\n",
        "If you want to play around with the code and change parameters, there are two alternatives:\n",
        "\n",
        "### Google's Colaboratory\n",
        "\n",
        "**Requires:** Google account\n",
        "\n",
        "1. Login to your Google Account\n",
        "2. Visit the link to the Notebook in Google's \"Colaboratory\":  \n",
        "   https://colab.research.google.com/github/penalab/systems-sound-localization/blob/master/Sys_Audio_Class.ipynb\n",
        "3. On the top-right, click \"Connect\" (or the little arrow right of it) and then \"Connect to hosted runtime\".\n",
        "4. Now you can \"run\" (mean: execute) the Python code of the individual code cells by clicking on the \"Play\" icon in the top-left corner of any cells containing Python code. After running the first code cell (the one with several lines starting with `import` near the beginning) once, you are free to play around.\n",
        "5. You can save your changes into your personal Google Drive or download the Notebook to your computer and run it locally (assuming you have Python installed).\n",
        "\n",
        "### Execute Jupyter locally\n",
        "\n",
        "**Requires:** Python 3 installed on your computer, plus at least `numpy`, `jupyter` and all of their dependencies. All of this comes bundles in the [Anaconda Distribution](https://www.anaconda.com/download/). Make sure you have Python 3.6 or 3.7.\n",
        "\n",
        "You can then download the Notebook file [Sys_Audio_Class.ipynb](https://github.com/penalab/systems-sound-localization/raw/master/Sys_Audio_Class.ipynb) from Github, place it in some directory where you find it in Jupyter and run it as usual.\n",
        "\n",
        "## Notes\n",
        "\n",
        "In between the Python Code cells (each having an input area with code and, possibly, an output area), there may be text areas (like this one). These are Markdown cells. If you accidentally start editing one of these, is looks less like nicely formatted text but more like a colored text editor. You can \"execute\" those cells in order to recover the formatted version."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ew_6LykusCbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x9MJeAXJsHLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrAna5GVr-7v"
      },
      "source": [
        "## What parameters to change?\n",
        "\n",
        "There are two functions `noise()` and `tone()` which are used to generate the examples below.\n",
        "\n",
        "Both functions display a small Audio element that you can use to play the generated sounds.\n",
        "\n",
        "To use one of the functions, just write their name followed imidiately by parenthesis, like this:\n",
        "\n",
        "```python\n",
        "noise()\n",
        "```\n",
        "\n",
        "or\n",
        "\n",
        "```python\n",
        "tone()\n",
        "```\n",
        "\n",
        "You can change parameters to non-default values by indicating this inside of the parenthesis. For example a tone with 1000 Hz instead of the default 440 Hz is generated like this:\n",
        "\n",
        "```python\n",
        "tone(freq = 1000)\n",
        "```\n",
        "\n",
        "**Do not include the units of the parameters. Only numbers are allowed. Decimals like `123.45` are usually allowed as well.**\n",
        "\n",
        "**All parameter names are _case sensitive_ (use all-lower-case).**\n",
        "\n",
        "### noise() parameters\n",
        "\n",
        "| parameter | default value | description\n",
        "| --------- | :------------ | :-------------\n",
        "| min_freq  | 20            | Lower end of the frequency range (pass-band) of the noise in Hz, must be positive.\n",
        "| max_freq  | 20000         | Upper end of the frequency range (pass-band) of the noise in Hz, must be greater than `min_freq` and should not be above 24000.\n",
        "| itd       | 0             | Interaural time difference in microseconds (µs).\n",
        "| ild       | 0             | Interaural level difference in decibel (dB).\n",
        "| bc        | +100          | Binaural correlation in percent, between -100 and +100.\n",
        "| length    | 1.0           | Length of the signal in seconds, keep it reasonable.\n",
        "| level     | 0             | Relative level in dB, can be negative or positive to decrease or increase the level. If you see a warning indicating that clipping occurred, the level is too high. The maximum value also depends on the actual ILD (and vice versa).\n",
        "\n",
        "For each parameter that you don't indicate explicitely, the default value will be used. In other words, using the `noise()` function without parameters is equivalent to (explicitely) setting all parameters to their default values:\n",
        "\n",
        "```python\n",
        "noise(min_freq = 20, max_freq = 20000, itd = 0, ild = 0, bc = 100, length = 1.0, level = 0)\n",
        "```\n",
        "\n",
        "### tone() parameters\n",
        "\n",
        "| parameter | default value | description\n",
        "| --------- | ------------- |:-------------\n",
        "| freq      | 440           | Frequency of the tone in Hz.\n",
        "| itd       | 0             | Interaural time difference in microseconds (µs).\n",
        "| ild       | 0             | Interaural level difference in decibel (dB).\n",
        "| length    | 1.0           | Length of the signal in seconds, keep it reasonable.\n",
        "| level     | 0             | Relative level in dB, can be negative or positive to decrease or increase the level. If you\n",
        "\n",
        "```python\n",
        "tone(freq = 440, itd = 0, ild = 0, bc = 100, length = 1.0, level = 0)\n",
        "```\n",
        "\n",
        "The other parameters of `noise()` and `tone()`, such as `ramp_dur`, `pad_length`, `show_player` and `return_signal`, are not actually needed to be changed in the sense of this class. But you are free to do so... maybe to learn more about Python.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NenpDNnMr-7y"
      },
      "outputs": [],
      "source": [
        "#####################################################\n",
        "## This code cell must be executed once before the ##\n",
        "## others. It defines all the necessary functions. ##\n",
        "#####################################################\n",
        "\n",
        "import numpy as np\n",
        "from IPython.display import Audio, HTML\n",
        "import struct\n",
        "from io import BytesIO\n",
        "import wave\n",
        "\n",
        "# Default sampling rate:\n",
        "samplingrate = 48000\n",
        "\n",
        "def db2amp(d):\n",
        "    return 10 ** (float(d) / 20)\n",
        "def amp2db(f):\n",
        "    return 20 * np.log10(f)\n",
        "\n",
        "def us2s(microseconds):\n",
        "    return microseconds * 1e-6\n",
        "def s2us(seconds):\n",
        "    return seconds * 1e6\n",
        "\n",
        "def ms2s(m_seconds):\n",
        "    return m_seconds * 1e-3\n",
        "def s2ms(seconds):\n",
        "    return seconds * 1e3\n",
        "\n",
        "def times(signal):\n",
        "    if isinstance(signal, (tuple, list)):\n",
        "        signal = signal[0]\n",
        "    return np.arange(signal.size)/samplingrate\n",
        "\n",
        "def signal_energy(signal, fs=100e3):\n",
        "    #signal = signal.astype(np.float64)\n",
        "    #print np.min(signal), np.max(signal)\n",
        "    return np.sum(signal.astype(np.float64) ** 2) / fs\n",
        "\n",
        "def signal_power(signal, fs=100e3):\n",
        "    return signal_energy(signal, fs=fs) / signal.size\n",
        "\n",
        "def band_limits(center=8500, octave_width=1.0):\n",
        "    return float(center) * 2**(-.5*octave_width), float(center) * 2**(+.5*octave_width)\n",
        "\n",
        "def to_stereo(signal):\n",
        "    \"\"\"Return a tuple of left and right signal\n",
        "    A single signal will be duplicated.\n",
        "    A stereo signal will be returned unchanged.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        signal_L, signal_R = signal\n",
        "        #print \"Play: Stereo\"\n",
        "    except ValueError:\n",
        "        signal_L = signal\n",
        "        signal_R = signal\n",
        "        #print \"Play: Mono\"\n",
        "    return (signal_L, signal_R)\n",
        "\n",
        "def ramp(x = None, start = 0.0, stop = 1.0, ramp_dur = .05, fs = None, amp = 1.0):\n",
        "    \"\"\"ramp(x = np.ones(fs), start = .400, stop = .500, ramp_dur = .05, fs = fs, amp = 1.0)\n",
        "\n",
        "    Ramp the signal x by linaer ramps between start and stop\n",
        "\n",
        "    Examples\n",
        "    ========\n",
        "\n",
        "    >>> ramp()\n",
        "    returns the default ramp function as it generates internally data x as all ones for 1 s with fs.\n",
        "    \"\"\"\n",
        "    if fs is None:\n",
        "        fs = samplingrate\n",
        "    if x is None:\n",
        "        x = np.ones(int(fs))\n",
        "    t1 = start\n",
        "    t2 = (start + ramp_dur)\n",
        "    t3 = (stop - ramp_dur)\n",
        "    t4 = stop\n",
        "    t = np.arange(x.size) / fs\n",
        "    r = amp * np.piecewise(t, [(t1 <= t) & (t < t2), (t2 <= t) & (t < t3), (t3 <= t) & (t < t4)],\n",
        "                         [lambda t: (t - t1) / (t2-t1), 1, lambda t: 1 - (t - t3) / (t4-t3), 0])\n",
        "    return r * x\n",
        "\n",
        "def bandpass_itd_noise(min_freq = 20, max_freq = 20000, itd=0, fs=None, samples = None):\n",
        "    \"\"\"bandpass_itd_noise()\n",
        "    \"\"\"\n",
        "    # Calculate available fft frequencies:\n",
        "    if fs is None:\n",
        "        fs = samplingrate\n",
        "    if samples is None:\n",
        "        samples = int(fs)\n",
        "    freqs = np.fft.rfftfreq(samples, 1/fs)\n",
        "    f = np.zeros_like(freqs)\n",
        "    idx = np.where(np.logical_and(freqs>=min_freq, freqs<=max_freq))[0]\n",
        "    f[idx] = 1 * np.sqrt(.5 * samples) * (f.size / np.count_nonzero(idx))**.5\n",
        "    f = np.array(f, dtype='complex')\n",
        "\n",
        "    phases_rad = np.random.rand(len(f)) * 2 * np.pi\n",
        "    phases = np.cos(phases_rad) + 1j * np.sin(phases_rad)\n",
        "\n",
        "    itd_phas_rad = us2s(itd) * np.pi * freqs #  * .5 * 2\n",
        "    shift_left = np.cos(-itd_phas_rad) + 1j * np.sin(-itd_phas_rad)\n",
        "    shift_right = np.cos(+itd_phas_rad) + 1j * np.sin(+itd_phas_rad)\n",
        "    phases_left = phases * shift_left\n",
        "    phases_right = phases * shift_right\n",
        "\n",
        "    f_left = f * phases_left\n",
        "    f_right = f * phases_right\n",
        "\n",
        "    s_left = np.fft.irfft(f_left).real\n",
        "    s_right = np.fft.irfft(f_right).real\n",
        "    return s_left, s_right\n",
        "\n",
        "def do_ild(signal, ild = 0):\n",
        "    signal_L, signal_R = to_stereo(signal)\n",
        "    amp_L = db2amp(-.5 * ild)\n",
        "    amp_R = db2amp(+.5 * ild)\n",
        "    return amp_L * signal_L, amp_R * signal_R\n",
        "\n",
        "def do_bc(signal, bc = 100, **noise_kwargs):\n",
        "    signal_L, signal_R = to_stereo(signal)\n",
        "    if bc != 100:\n",
        "        if bc < 0:\n",
        "            signal_R = -signal_R\n",
        "        r = abs(bc / 100)\n",
        "        _, decorr_noise_L = bandpass_itd_noise(itd=0, **noise_kwargs)\n",
        "        _, decorr_noise_R = bandpass_itd_noise(itd=0, **noise_kwargs)\n",
        "        # Adjust powers:\n",
        "        decorr_noise_L = decorr_noise_L / (signal_power(decorr_noise_L) / signal_power(signal_L))**.5\n",
        "        decorr_noise_R = decorr_noise_R / (signal_power(decorr_noise_R) / signal_power(signal_R))**.5\n",
        "        signal_L = r**.5 * signal_L + (1 - r)**.5 * decorr_noise_L\n",
        "        signal_R = r**.5 * signal_R + (1 - r)**.5 * decorr_noise_R\n",
        "    return signal_L, signal_R\n",
        "\n",
        "def stack(*signals):\n",
        "    n = len(signals)\n",
        "    signal_stack = tuple(np.sum(np.stack([s[c] for s in signals]), axis=0) / np.sqrt(n) for c in (0, 1))\n",
        "    return signal_stack\n",
        "\n",
        "def pscale(signal, rel_power=1.0):\n",
        "    scaled_signal = tuple(signal[c] * np.sqrt(rel_power) for c in (0, 1))\n",
        "    return scaled_signal\n",
        "\n",
        "def player(signal, rel_abi=0):\n",
        "    # Make it stereo and stack in one\n",
        "    signal = np.vstack(to_stereo(signal))\n",
        "    scaled = signal.T.ravel() * 1024 * db2amp(rel_abi)\n",
        "    if np.max(np.abs(scaled)) > 32767:\n",
        "        scale_by = 32767 / np.max(np.abs(scaled))\n",
        "        scaled = scaled * scale_by\n",
        "        import sys\n",
        "        print(f\"Signal would have clipped. Scaled (down) by {amp2db(scale_by):.1g} dB.\", file=sys.stderr)\n",
        "    fp = BytesIO()\n",
        "    waveobj = wave.open(fp,mode='wb')\n",
        "    waveobj.setnchannels(2)\n",
        "    waveobj.setframerate(samplingrate)\n",
        "    waveobj.setsampwidth(2)\n",
        "    waveobj.setcomptype('NONE','NONE')\n",
        "    waveobj.writeframes(b''.join([struct.pack('<h',x) for x in np.int16(scaled)]))\n",
        "    pmc_data = fp.getvalue()\n",
        "    waveobj.close()\n",
        "    display(Audio(pmc_data, rate=samplingrate, autoplay=False))\n",
        "\n",
        "def save_wave(signal, filename, rel_abi=0):\n",
        "    # Make it stereo and stack in one\n",
        "    signal = np.vstack(to_stereo(signal))\n",
        "    scaled = signal.T.ravel() * 1024 * db2amp(rel_abi)\n",
        "    if np.max(np.abs(scaled)) > 32767:\n",
        "        scale_by = 32767 / np.max(np.abs(scaled))\n",
        "        scaled = scaled * scale_by\n",
        "        import sys\n",
        "        print(f\"Signal would have clipped. Scaled (down) by {amp2db(scale_by):.1g} dB.\", file=sys.stderr)\n",
        "    with open(filename, 'wb') as fp:\n",
        "        waveobj = wave.open(fp,mode='wb')\n",
        "        waveobj.setnchannels(2)\n",
        "        waveobj.setframerate(samplingrate)\n",
        "        waveobj.setsampwidth(2)\n",
        "        waveobj.setcomptype('NONE','NONE')\n",
        "        waveobj.writeframes(b''.join([struct.pack('<h',x) for x in np.int16(scaled)]))\n",
        "        waveobj.close()\n",
        "\n",
        "def noise(min_freq = 20, max_freq = 20000, itd=0, ild=0, bc=100, length=1.0, level=0, ramp_dur=0.05, pad_length=0.005, show_player=True, return_signal=False):\n",
        "    samples = int((length + 2 * pad_length) * samplingrate)\n",
        "    signal_LR = bandpass_itd_noise(min_freq, max_freq, itd, samplingrate, samples)\n",
        "    signal_LR = do_bc(signal_LR, bc=bc, min_freq=min_freq, max_freq=max_freq, fs=samplingrate, samples=samples)\n",
        "    signal_LR = do_ild(signal_LR, ild)\n",
        "    signal_LR = [ramp(s, start=pad_length, stop=length+pad_length, ramp_dur=ramp_dur) for s in signal_LR]\n",
        "    if show_player:\n",
        "        display(HTML(f'<p><strong>Noise</strong> {min_freq}-{max_freq} Hz, '\n",
        "                     f'ITD = {itd} μs, ILD = {ild} dB, BC = {bc}%'\n",
        "                     '</p><style type=\"text/css\">audio {min-width: 400px; }</style>'))\n",
        "        player(signal_LR, rel_abi=level)\n",
        "    if return_signal:\n",
        "        return signal_LR\n",
        "\n",
        "def tone(freq = 440, itd=0, ild=0, bc=100, length=1.0, level=0, ramp_dur=0.05, pad_length=0.005, show_player=True, return_signal=False, **bc_noise_kwargs):\n",
        "    samples = int((length + 2 * pad_length) * samplingrate)\n",
        "    t = np.arange(0, samples) / samplingrate\n",
        "    phase = np.random.rand(1) * 2 * np.pi\n",
        "    shift = us2s(itd) * np.pi * freq\n",
        "    signal_LR = (\n",
        "        np.sin(t * 2 * np.pi * freq + phase - shift),\n",
        "        np.sin(t * 2 * np.pi * freq + phase + shift)\n",
        "    )\n",
        "    signal_LR = do_bc(signal_LR, bc=bc, fs=samplingrate, samples=samples, **bc_noise_kwargs)\n",
        "    signal_LR = do_ild(signal_LR, ild)\n",
        "    signal_LR = [ramp(s, start=pad_length, stop=length+pad_length, ramp_dur=ramp_dur) for s in signal_LR]\n",
        "    if show_player:\n",
        "        display(HTML(f'<p><strong>Tone</strong> {freq} Hz, '\n",
        "                     f'ITD = {itd} μs, ILD = {ild} dB, BC = {bc}%'\n",
        "                     '</p><style type=\"text/css\">audio {min-width: 400px; }</style>'))\n",
        "        player(signal_LR, rel_abi=level)\n",
        "    if return_signal:\n",
        "        return signal_LR\n",
        "\n",
        "def tone_stack(freqs = np.arange(500, 12000, 1000), show_player=True, return_signal=False, show_single_player=False, **tone_kwargs):\n",
        "    tone_kwargs.update(show_player=show_single_player)\n",
        "    tone_kwargs.update(return_signal=True)\n",
        "    signal_LR = stack(*[tone(freq=f, **tone_kwargs) for f in freqs])\n",
        "    if show_player:\n",
        "        display(HTML(f'<p><strong>Tone-Stack</strong> {freqs} Hz, '\n",
        "                     f'ITD = {tone_kwargs.get(\"itd\",0)} μs, ILD = {tone_kwargs.get(\"ild\",0)} dB, BC = {tone_kwargs.get(\"bc\",100)}%'\n",
        "                     '</p><style type=\"text/css\">audio {min-width: 400px; }</style>'))\n",
        "        player(signal_LR)\n",
        "    if return_signal:\n",
        "        return signal_LR\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCXssnr5r-71"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-M4Pepzr-73"
      },
      "outputs": [],
      "source": [
        "d = {}\n",
        "for itd in np.linspace(-900, 900, 13, dtype='int'):\n",
        "#     print(itd)\n",
        "    s = noise(itd=itd, min_freq=60, max_freq=6000, length=.5, pad_length=0, ramp_dur=0, show_player=False, return_signal=True)\n",
        "    savedir = r\"C:\\Users\\roland\\Documents\\Teaching\\Systems Audio\\2020\"\n",
        "    savename = f'./noise_itd/itd{itd:+04d}.wav'\n",
        "    savepath = os.path.join(savedir, savename)\n",
        "    if not os.path.exists(os.path.dirname(savepath)):\n",
        "        os.mkdir(os.path.dirname(savepath))\n",
        "    save_wave(s, savepath)\n",
        "    d[str(itd)] = savename\n",
        "print('var sounds = ', json.dumps(d, indent=4), ';', sep='')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK2meXW6r-73"
      },
      "source": [
        "## Localize Broadband Noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4fbw8OXr-74"
      },
      "source": [
        "The following two cells include each several 0.5-second (500ms) broadband noise samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V3AA8uSr-75"
      },
      "source": [
        "### ITD\n",
        "\n",
        "In the first cell, the __interaural time differnce (ITD)__ was varied.\n",
        "\n",
        "By convention, _negative ITDs_ indicate that the sound presented to the _left_ ear is leading, _positive ITDs_ indicate that the sound presented to the _right_ ear is leading.\n",
        "\n",
        "This kind of sound that include \"only\" ITD information is usually perceived \"inside the head\", i.e. it is internalized. However, sound with different ITDs should be clearly shifted inside the head according to the ITD value.\n",
        "\n",
        "Listen to the different sound samples - it's easiest to start with the one that has `ITD = 0 µs`. Check your own ITD range and correlate perceptual effects with ITD values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8eNKe_0r-77"
      },
      "outputs": [],
      "source": [
        "for itd in [-4800, -2400, -1200, -900, -750, -600, -450, -300, -150, 0, 150, 300, 450, 600, 750, 900, 1200, 2400, 4800]:\n",
        "    noise(itd=itd, length=.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7YCo0vHr-79"
      },
      "source": [
        "### ILD\n",
        "\n",
        "In the second cell, the __interaural level differnce (ILD)__ was varied.\n",
        "\n",
        "By convention, _negative ILDs_ indicate that the sound presented to the _left_ ear is louder, _positive ILDs_ indicate that the sound presented to the _right_ ear is louder.\n",
        "\n",
        "Like ITD-only sounds, ILD-only sounds are internalized. The most extreme ILD values may actually sound like noise is presented to one ear alone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFdgzcvAr-7-"
      },
      "outputs": [],
      "source": [
        "for ild in [-40, -30, -20, -15, -10, -5, 0, 5, 10, 15, 20, 30, 40]:\n",
        "    noise(ild=ild, length=.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-amsw3Pr-7_"
      },
      "source": [
        "# ITD detection varying frequency and bandwidth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfq5Dulnr-7_"
      },
      "source": [
        "The unambiguous detection of ITD depends on the frequencies available in a sound stimulus.\n",
        "\n",
        "First, there is an upper limit of frequencies above which auditory nerve fibers cannot pass time (or phase) information. This limit is different between species.\n",
        "\n",
        "Listen to the following pure tones, all at an ITD of +600 μs (right), with increasing frequencies.\n",
        "\n",
        "Up to which frequency do you perceive the tone at the right side? At which frequencies do you perceive it more in the center or not localized at all?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kqe4x5Irr-8A"
      },
      "outputs": [],
      "source": [
        "for freq in [150, 300, 450, 600, 750, 900, 1050, 1200, 1350, 1500, 1800, 2100, 2400, 2700, 3000, 4000, 6000, 8000]:\n",
        "    tone(freq=freq, itd=600, length=.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktNW8OaJr-8B"
      },
      "source": [
        "We can further explore our (lacking) capability of the to detect ITDs at high frequencies.\n",
        "\n",
        "Let's first use some tones and narrow band noises in the low frequency range, i.e. at or around 500 Hz.\n",
        "\n",
        "You should be able to localize these toward the left/right depending on the individual ITD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NXKiujDr-8B"
      },
      "outputs": [],
      "source": [
        "cf = 500 # frequency or center frequency in Hz\n",
        "\n",
        "for itd in [-500, -250, 0, 250, 500]:\n",
        "    tone(freq=cf, itd=itd, length=.5)\n",
        "\n",
        "bw = 400 # bandwidth in Hz\n",
        "for itd in [-500, -250, 0, 250, 500]:\n",
        "    noise(min_freq=cf-bw/2, max_freq=cf+bw/2, itd=itd, length=.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJoSG-V7r-8B"
      },
      "source": [
        "Using a higher (center) frequency, removes our capability to detect ITDs. Here we use 7000 Hz (7 kHz)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzwjk2Edr-8C"
      },
      "outputs": [],
      "source": [
        "cf = 7000 # frequency or center frequency in Hz\n",
        "\n",
        "for itd in [-500, -250, 0, 250, 500]:\n",
        "    tone(freq=cf, itd=itd, length=.5)\n",
        "\n",
        "bw = 400 # bandwidth in Hz\n",
        "for itd in [-500, -250, 0, 250, 500]:\n",
        "    noise(min_freq=cf-bw/2, max_freq=cf+bw/2, itd=itd, length=.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8Thvz-Ur-8D"
      },
      "source": [
        "## Ambigious signals, a central/frontal bias and its resolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKIBQIV5r-8E"
      },
      "source": [
        "An interesting effect arises when we use a combination of frequencies and ITDs that leads to \"false\" impressions.\n",
        "\n",
        "To experience this effect, we use a (center) frequency of 714 Hz - we've seen above that ITDs can be detected at this frequency range. You can try this here again. Start at ITD=0, then progressively go to higher ITDs.\n",
        "\n",
        "What to you experience when you reach ITDs close to the period $T={1 \\over f}$ of this frequency? Compare this to the negative ITDs.\n",
        "\n",
        "**Explanation (read after trying yourself):** The periodic nature of tones leads to a \"falsy\" detection of ITD when the absolute values of ITD reach the period corresponding to a tone's frequency. When two tones (sine waves) of the same frequency are cross-correlated to determine the time lag between them (which is equal to the ITD), multiple ambiguous solutions are possible, apart from each other by the the period of the used frequency. The actual percept that arises is biased toward the front, i.e. the smallest absolute ITD value is assumed. For a frequency of 714 Hz, this mean that ITD = 0 μs and ITD = +1400 μs are effectively the same, as are -200 and 1200 μs, -400 and +1000 μs, -700 and +700 μs, and so on..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDcQTXGMr-8E"
      },
      "outputs": [],
      "source": [
        "f = 714\n",
        "print(f\"The period of f = {f} Hz is approx. T = {1/f*1e6:.0f} μs\")\n",
        "for itd in [-400, -200, 0, 200, 400, 600, 800, 1000, 1200, 1400, 1600]:\n",
        "    tone(freq=f, itd=itd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AScgfM_Sr-8E"
      },
      "source": [
        "However, the ambiguities observed in pure tones and narrow band noises can be cancelled out by increasing the bandwidth, i.e. by \"adding\" more frequencies to the signal.\n",
        "\n",
        "The next samples all use ITD = 1200 μs and a center frequency of 714 Hz. Start at the smallest bandwidth (here 1 Hz is effectively only a tone due to the method used to generate the stimuli) and experience how the perceived location of the stimulus changes with increasing bandwidth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjwCSD3Hr-8E"
      },
      "outputs": [],
      "source": [
        "cf = 714\n",
        "for bw in [1, 50, 150, 250, 350, 500, 800, 1000]:\n",
        "    print(f\"Bandwidth: {bw} Hz\")\n",
        "    noise(min_freq=cf-bw/2, max_freq=cf+bw/2, itd=1200, ramp_dur=.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5vtECLzr-8F"
      },
      "source": [
        "## Envelope ITD detection at high frequencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82dWvckxr-8G"
      },
      "source": [
        "We have seen before that it is not possible to detect ITDs at high frequency tones or even narrowband noises containing a range of high frequencies.\n",
        "\n",
        "If we use a wide enough range of frequencies, however, the so called envelope (random changes in sound intensity) which always has a lower frequency, may be used to detect ITD.\n",
        "\n",
        "Let's test this with just two ITDs: -400 μs (left) and +400 μs (right). Verify that you cannot hear any difference between the two ITDs of tones at 4 kHz and 8 kHz. Then see if the same is true for a noise containing all frequencies in between."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49GE1TQ9r-8H"
      },
      "outputs": [],
      "source": [
        "tone(freq=4000, itd=-400)\n",
        "tone(freq=4000, itd=400)\n",
        "\n",
        "tone(freq=8000, itd=-400)\n",
        "tone(freq=8000, itd=400)\n",
        "\n",
        "noise(min_freq=4000, max_freq=8000, itd=-400)\n",
        "noise(min_freq=4000, max_freq=8000, itd=400)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1pmgr0ar-8I"
      },
      "source": [
        "# Binaural Correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuUOVGs3r-8I"
      },
      "source": [
        "As mentionned earlier, the mechanism to detect ITDs is similar to the cross-correlation. As we have seen, the success of this detection depends on the frequencies contained in the signal - in a perfect world.\n",
        "\n",
        "In nature (and in the lab), the correlation between the two signals arriving at (or presented to) the two ears may be impaired. This could be due to other sounds arriving at the same time or due to noise that reaches the ears nearly independently. Neuronal noise may also play a role in deteriorating the signal quality before cross-correlation can be computed in the brain (e.g. via the Jeffress model in the avian brain).\n",
        "\n",
        "We can mimick the effect by adding independent noise to the signals presented to both ears. This independent noise carries no ITD information. The amount of noise added is expressed as _binaural correlation_ (BC) where 100% indicate a perfectly correlated signal and 0% indicate that only indepentent noise is presented.\n",
        "\n",
        "Below, you can experience different levels of binaural correlation. Start with the first three examples (BC = 100%) and work your way down to lower BC values. What do you experience? Can you still localize the signal at low BC values (distiguish the three different ITDs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVkF4G-Dr-8I"
      },
      "outputs": [],
      "source": [
        "for bc in [100, 80, 60, 40, 20, 0]:\n",
        "    print(f\"Binaural Correlation {bc}%\")\n",
        "    noise(itd=-400, bc=bc)\n",
        "    noise(itd=   0, bc=bc)\n",
        "    noise(itd= 400, bc=bc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WvM_1m3r-8J"
      },
      "source": [
        "# Time-intensity trade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk5hsQfBr-8J"
      },
      "source": [
        "We have seen that ITD and ILD can both be used alone to shift the perceived location of a signal to the left or to the right - while the other value is kept at zero.\n",
        "\n",
        "Natually, ITD and ILD would both vary depending on the sound source location and their effect would be combined.\n",
        "\n",
        "In the current artificial situation (using headphonse/earphonse) where we can control ITD and ILD independently, it is possible to set them to contradictory values (i.e. combinations that wouldn't normally occur with real sound sources). This helps to determine how much influence each of these cues actually has on the perceived location of a sound and how they are combined."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o5XjYE3r-8K"
      },
      "source": [
        "Here is a first sound with ITD and ILD set to zero to give you again a reference how a central/frontal stimulus sounds like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bU2KpVXir-8K"
      },
      "outputs": [],
      "source": [
        "noise(itd=0, ild=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH2ZZgUkr-8L"
      },
      "source": [
        "All of the following samples have an ITD set to +300 μs. At the same time, they have a different ILDs, starting at 0 dB and progressively decreasing toward -15 dB.\n",
        "\n",
        "Keep in mind that positive values of ITD and ILD are associated with stimuli on the right, negative values on the left.\n",
        "\n",
        "Decrease the ILD step-by-step to move the stimulus back to the center/front. Which ILD \"cancels out\" the right shift given by the fixed ITD?\n",
        "\n",
        "Note that even the most central/frontal combination will unlikely sound exactly the same as the reference above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtavhYfEr-8M"
      },
      "outputs": [],
      "source": [
        "for ild in [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15]:\n",
        "    noise(itd=300, ild=ild)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}